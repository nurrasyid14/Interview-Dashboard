# ğŸ§¹ Preprocessor Module

Part of the AI Interviewer backend pipeline.
Handles data ingestion, cleaning, and linguistic feature preparation from raw speech or text.

## ğŸ“¦ Overview

The Preprocessor is responsible for converting raw, multilingual audio and textual input from interview sessions into clean, structured, and analyzable data.
It forms the foundation for downstream processes like feature extraction, sentiment analysis, and decision modeling.

This module is composed of three key blocks:
```
preprocessor/
â”‚
â”œâ”€â”€ ingestion/          # Handles data input, transcription, and translation
â”œâ”€â”€ text_cleaning/      # Normalization, tokenization, stopword removal, etc.
â””â”€â”€ linguistics/        # Lemmatization, stemming, and POS tagging
```
## ğŸ§© Submodules
### 1. Ingestion

Handles all raw input sources â€” including audio, text, and multilingual data streams.

Components:

input_handler.py â†’ Manages incoming data from APIs, forms, or chat pipelines.

audio_transcriber.py â†’ Converts .wav, .mp3, or live audio into text using speech_recognition.

translator.py â†’ Auto-translates non-English input into the projectâ€™s target analysis language via supported translation APIs.

### 2. Text Cleaning

Cleans and normalizes text before linguistic and ML processing.

Components:

normalizer.py â†’ Lowercasing, punctuation removal, symbol cleanup.

tokenizer.py â†’ Sentence/word-level tokenization using nltk or spaCy.

stopwords_remover.py â†’ Removes irrelevant tokens.

ğŸ§  Tip: This stage ensures that the AI model focuses only on meaningful linguistic signals rather than noise.

### 3. Linguistics

Adds higher-level NLP structure for feature extraction.

Components:

lemma_stem.py â†’ Performs stemming and lemmatization.

tagger.py â†’ Part-of-speech tagging for syntactic context and feature engineering.

## ğŸ§  Processing Flow
Audio/Text Input
     â†“
Ingestion â†’ Translation
     â†“
Text Cleaning â†’ Tokenization â†’ Stopword Removal
     â†“
Linguistics â†’ Lemmatization â†’ Tagging
     â†“
Feature Extraction (next block)


Each stage outputs standardized, language-agnostic text vectors ready for feature engineering and learning models.

## ğŸ§° Requirements
```
nltk
spacy
scikit-learn
speechrecognition
pydub
numpy
```

## ğŸ—£ï¸ For multilingual support, install the spaCy model(s) you need:
```
python -m spacy download en_core_web_md
python -m spacy download id_core_news_md
python -m spacy download xx_ent_wiki_sm
```
## âš™ï¸ Usage Example
``` py
from preprocessor.ingestion.audio_transcriber import AudioTranscriber
from preprocessor.text_cleaning.normalizer import TextNormalizer
from preprocessor.linguistics.lemma_stem import LemmaStemmer


# 1ï¸âƒ£ Transcribe audio
# transcriber = AudioTranscriber()
# text = transcriber.transcribe("input/interview_sample.wav")

# 2ï¸âƒ£ Normalize
normalizer = TextNormalizer()
clean_text = normalizer.clean(text)

# 3ï¸âƒ£ Lemmatize
lemmatizer = LemmaStemmer(lang="en")
processed = lemmatizer.process(clean_text)

print(processed)
```

## ğŸ§© Integration Notes

This module feeds into:

feature_extracting/ â†’ to build text vectors (TF-IDF, embeddings, etc.)

subset_selection/ â†’ for cross-validation

ensemble_learning/ â†’ for decision modeling

visualizer/ â†’ for output dashboards
